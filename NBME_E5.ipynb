{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NBME_E5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyODAPq/5GKNIMyYgQ+V/NnB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/piyushpradhan22/MLChallenge/blob/master/NBME_E5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"kaggle.json\", 'w')\n",
        "f.write(\"{\\\"username\\\":\\\"piyushpradhan22\\\",\\\"key\\\":\\\"59c6ae034f7e7db2f2740d65be499b09\\\"}\")\n",
        "f.close()\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "UUCWMbU-0xji"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\"\"\"\n",
        "!kaggle competitions download -c nbme-score-clinical-patient-notes\n",
        "!unzip -o /content/nbme-score-clinical-patient-notes.zip\n",
        "#\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzezaNY407dZ",
        "outputId": "817b2e5a-6cdc-4ab7-8063-e2f8ed4db8cc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nbme-score-clinical-patient-notes.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  /content/nbme-score-clinical-patient-notes.zip\n",
            "  inflating: features.csv            \n",
            "  inflating: patient_notes.csv       \n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "Wmvqrkar1NvR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path=''"
      ],
      "metadata": {
        "id": "Ny2p6YfO1ACo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from transformers import TFAutoModel, AutoTokenizer"
      ],
      "metadata": {
        "id": "NuDjdPon1MaS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv(path+\"train.csv\")\n",
        "df2 = pd.read_csv(path+\"patient_notes.csv\")\n",
        "df3 = pd.read_csv(path+\"features.csv\")\n",
        "df4 = pd.read_csv(path+\"test.csv\")\n",
        "df_test = pd.merge(df4, df2, how='left', on = 'pn_num').merge(df3, how = 'left', on = 'feature_num')\n",
        "df = pd.merge(df1, df2, how='left', on = 'pn_num').merge(df3, how = 'left', on = 'feature_num') ; del df1, df2, df3,df4\n",
        "df.pn_history = df.pn_history.str.lower()\n",
        "df.annotation = df.annotation.str.lower()\n",
        "df.drop(columns=['case_num_x','case_num_y'], inplace=True)"
      ],
      "metadata": {
        "id": "8Dpx-jQm1Gyw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# incorrect annotation\n",
        "df.loc[338, 'annotation'] = '[\"father heart attack\"]'\n",
        "df.loc[338, 'location'] = '[\"764 783\"]'\n",
        "\n",
        "df.loc[621, 'annotation'] = '[\"for the last 2-3 months\"]'\n",
        "df.loc[621, 'location'] = '[\"77 100\"]'\n",
        "\n",
        "df.loc[655, 'annotation'] = '[\"no heat intolerance\",\"no cold intolerance\"]'\n",
        "df.loc[655, 'location'] = '[\"285 292;301 312\",\"285 287;296 312\"]'\n",
        "\n",
        "df.loc[1262, 'annotation'] = '[\"mother thyroid problem\"]'\n",
        "df.loc[1262, 'location'] = '[\"551 557;565 580\"]'\n",
        "\n",
        "df.loc[1265, 'annotation'] = '[\\'felt like he was going to \"pass out\"\\']'\n",
        "df.loc[1265, 'location'] = '[\"131 135;181 212\"]'\n",
        "\n",
        "df.loc[1396, 'annotation'] = '[\"stool , with no blood\"]'\n",
        "df.loc[1396, 'location'] = '[\"259 280\"]'\n",
        "\n",
        "df.loc[1591, 'annotation'] = '[\"diarrhoe non blooody\"]'\n",
        "df.loc[1591, 'location'] = '[\"176 184;201 212\"]'\n",
        "\n",
        "df.loc[1615, 'annotation'] = '[\"diarrhea for last 2-3 days\"]'\n",
        "df.loc[1615, 'location'] = '[\"249 257;271 288\"]'\n",
        "\n",
        "df.loc[1664, 'annotation'] = '[\"no vaginal discharge\"]'\n",
        "df.loc[1664, 'location'] = '[\"822 824;907 924\"]'\n",
        "\n",
        "df.loc[1714, 'annotation'] = '[\"started about 8-10 hours ago\"]'\n",
        "df.loc[1714, 'location'] = '[\"101 129\"]'\n",
        "\n",
        "df.loc[1929, 'annotation'] = '[\"no blood in the stool\"]'\n",
        "df.loc[1929, 'location'] = '[\"531 539;549 561\"]'\n",
        "\n",
        "df.loc[2134, 'annotation'] = '[\"last sexually active 9 months ago\"]'\n",
        "df.loc[2134, 'location'] = '[\"540 560;581 593\"]'\n",
        "\n",
        "df.loc[2191, 'annotation'] = '[\"right lower quadrant pain\"]'\n",
        "df.loc[2191, 'location'] = '[\"32 57\"]'\n",
        "\n",
        "df.loc[2553, 'annotation'] = '[\"diarrhoea no blood\"]'\n",
        "df.loc[2553, 'location'] = '[\"308 317;376 384\"]'\n",
        "\n",
        "df.loc[3124, 'annotation'] = '[\"sweating\"]'\n",
        "df.loc[3124, 'location'] = '[\"549 557\"]'\n",
        "\n",
        "df.loc[3858, 'annotation'] = '[\"previously as regular\",\"previously eveyr 28-29 days\",\"previously lasting 5 days\",\"previously regular flow\"]'\n",
        "df.loc[3858, 'location'] = '[\"102 123\",\"102 112;125 141\",\"102 112;143 157\",\"102 112;159 171\"]'\n",
        "\n",
        "df.loc[4373, 'annotation'] = '[\"for 2 months\"]'\n",
        "df.loc[4373, 'location'] = '[\"33 45\"]'\n",
        "\n",
        "df.loc[4763, 'annotation'] = '[\"35 year old\"]'\n",
        "df.loc[4763, 'location'] = '[\"5 16\"]'\n",
        "\n",
        "df.loc[4782, 'annotation'] = '[\"darker brown stools\"]'\n",
        "df.loc[4782, 'location'] = '[\"175 194\"]'\n",
        "\n",
        "df.loc[4908, 'annotation'] = '[\"uncle with peptic ulcer\"]'\n",
        "df.loc[4908, 'location'] = '[\"700 723\"]'\n",
        "\n",
        "df.loc[6016, 'annotation'] = '[\"difficulty falling asleep\"]'\n",
        "df.loc[6016, 'location'] = '[\"225 250\"]'\n",
        "\n",
        "df.loc[6192, 'annotation'] = '[\"helps to take care of aging mother and in-laws\"]'\n",
        "df.loc[6192, 'location'] = '[\"197 218;236 260\"]'\n",
        "\n",
        "df.loc[6380, 'annotation'] = '[\"No hair changes\",\"No skin changes\",\"No GI changes\",\"No palpitations\",\"No excessive sweating\"]'\n",
        "df.loc[6380, 'location'] = '[\"480 482;507 519\",\"480 482;499 503;512 519\",\"480 482;521 531\",\"480 482;533 545\",\"480 482;564 582\"]'\n",
        "\n",
        "df.loc[6562, 'annotation'] = '[\"stressed due to taking care of her mother\",\"stressed due to taking care of husbands parents\"]'\n",
        "df.loc[6562, 'location'] = '[\"290 320;327 337\",\"290 320;342 358\"]'\n",
        "\n",
        "df.loc[6862, 'annotation'] = '[\"stressor taking care of many sick family members\"]'\n",
        "df.loc[6862, 'location'] = '[\"288 296;324 363\"]'\n",
        "\n",
        "df.loc[7022, 'annotation'] = '[\"heart started racing and felt numbness for the 1st time in her finger tips\"]'\n",
        "df.loc[7022, 'location'] = '[\"108 182\"]'\n",
        "\n",
        "df.loc[7422, 'annotation'] = '[\"first started 5 yrs\"]'\n",
        "df.loc[7422, 'location'] = '[\"102 121\"]'\n",
        "\n",
        "df.loc[8876, 'annotation'] = '[\"No shortness of breath\"]'\n",
        "df.loc[8876, 'location'] = '[\"481 483;533 552\"]'\n",
        "\n",
        "df.loc[9027, 'annotation'] = '[\"recent URI\",\"nasal stuffines, rhinorrhea, for 3-4 days\"]'\n",
        "df.loc[9027, 'location'] = '[\"92 102\",\"123 164\"]'\n",
        "\n",
        "df.loc[9938, 'annotation'] = '[\"irregularity with her cycles\",\"heavier bleeding\",\"changes her pad every couple hours\"]'\n",
        "df.loc[9938, 'location'] = '[\"89 117\",\"122 138\",\"368 402\"]'\n",
        "\n",
        "df.loc[9973, 'annotation'] = '[\"gaining 10-15 lbs\"]'\n",
        "df.loc[9973, 'location'] = '[\"344 361\"]'\n",
        "\n",
        "df.loc[10513, 'annotation'] = '[\"weight gain\",\"gain of 10-16lbs\"]'\n",
        "df.loc[10513, 'location'] = '[\"600 611\",\"607 623\"]'\n",
        "\n",
        "df.loc[11551, 'annotation'] = '[\"seeing her son knows are not real\"]'\n",
        "df.loc[11551, 'location'] = '[\"386 400;443 461\"]'\n",
        "\n",
        "df.loc[11677, 'annotation'] = '[\"saw him once in the kitchen after he died\"]'\n",
        "df.loc[11677, 'location'] = '[\"160 201\"]'\n",
        "\n",
        "df.loc[12124, 'annotation'] = '[\"tried Ambien but it didnt work\"]'\n",
        "df.loc[12124, 'location'] = '[\"325 337;349 366\"]'\n",
        "\n",
        "df.loc[12279, 'annotation'] = '[\"heard what she described as a party later than evening these things did not actually happen\"]'\n",
        "df.loc[12279, 'location'] = '[\"405 459;488 524\"]'\n",
        "\n",
        "df.loc[12289, 'annotation'] = '[\"experienced seeing her son at the kitchen table these things did not actually happen\"]'\n",
        "df.loc[12289, 'location'] = '[\"353 400;488 524\"]'\n",
        "\n",
        "df.loc[13238, 'annotation'] = '[\"SCRACHY THROAT\",\"RUNNY NOSE\"]'\n",
        "df.loc[13238, 'location'] = '[\"293 307\",\"321 331\"]'\n",
        "\n",
        "df.loc[13297, 'annotation'] = '[\"without improvement when taking tylenol\",\"without improvement when taking ibuprofen\"]'\n",
        "df.loc[13297, 'location'] = '[\"182 221\",\"182 213;225 234\"]'\n",
        "\n",
        "df.loc[13299, 'annotation'] = '[\"yesterday\",\"yesterday\"]'\n",
        "df.loc[13299, 'location'] = '[\"79 88\",\"409 418\"]'\n",
        "\n",
        "df.loc[13845, 'annotation'] = '[\"headache global\",\"headache throughout her head\"]'\n",
        "df.loc[13845, 'location'] = '[\"86 94;230 236\",\"86 94;237 256\"]'\n",
        "\n",
        "df.loc[14083, 'annotation'] = '[\"headache generalized in her head\"]'\n",
        "df.loc[14083, 'location'] = '[\"56 64;156 179\"]'"
      ],
      "metadata": {
        "id": "AXW_bNMD1JCN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.annotation = df.annotation.apply(lambda x: ast.literal_eval(x))\n",
        "df.location = df.location.apply(lambda x: ast.literal_eval(x))"
      ],
      "metadata": {
        "id": "btdtqi_I1cAD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NEW on TPU in TensorFlow 24: shorter cross-compatible TPU/GPU/multi-GPU/cluster-GPU detection code\n",
        "\n",
        "try: # detect TPUs\n",
        "    tpu  = tf.distribute.cluster_resolver.TPUClusterResolver.connect() # TPU detection\n",
        "    tf.config.experimental_connect_to_cluster(tpu )\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu )\n",
        "    strategy = tf.distribute.TPUStrategy(tpu )\n",
        "    print('Using TPU')\n",
        "except ValueError: # detect GPUs\n",
        "    tpu = None\n",
        "    strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n",
        "    #strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n",
        "\n",
        "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)\n",
        "\n",
        "\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "REPLICAS = strategy.num_replicas_in_sync\n",
        "print(f'REPLICAS: {REPLICAS}')"
      ],
      "metadata": {
        "id": "xUvuRLai1lBP",
        "outputId": "d3606e8f-cc3c-415f-c23f-cb811d9e0c76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "Number of accelerators:  1\n",
            "REPLICAS: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'bert-base-uncased'"
      ],
      "metadata": {
        "id": "dOE0b3BT1d22"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME,normalization=True)"
      ],
      "metadata": {
        "id": "nfyOa7VK1gCG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getExpanded(x):\n",
        "    ex_list = []\n",
        "    for val in x:\n",
        "        lst = val.split(\";\")\n",
        "        for lst1 in lst:\n",
        "            lst2 = lst1.split(\" \")\n",
        "            ex_list.extend(list(range(int(lst2[0]), int(lst2[1]))))\n",
        "    return ex_list"
      ],
      "metadata": {
        "id": "gGjg1riuDT1z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEQUENCE_LENGTH = 512\n",
        "def buildTrainingData(df):\n",
        "  input_ids = []\n",
        "  attention_mask = []\n",
        "  offset_mapping = []\n",
        "  answer = []\n",
        "  \n",
        "  for i in tqdm(range(len(df))):\n",
        "    x = tokenizer.encode_plus(df.loc[i].pn_history, max_length=SEQUENCE_LENGTH, padding='max_length',truncation=True, return_offsets_mapping=True)\n",
        "    input_ids.append(x['input_ids'])\n",
        "    attention_mask.append(x['attention_mask'])\n",
        "    offset_mapping.append(x['offset_mapping'])\n",
        "    answer.append([1 if x['offset_mapping'][j][0] in getExpanded(df.location.values[i]) else 0 for j in range(SEQUENCE_LENGTH)])\n",
        "    \n",
        "  return np.vstack(input_ids), np.vstack(attention_mask), offset_mapping, np.vstack(answer)\n",
        "\n",
        "def buildTestData(df):\n",
        "  input_ids = []\n",
        "  attention_mask = []\n",
        "  offset_mapping = []\n",
        "  \n",
        "  for i in tqdm(range(len(df))):\n",
        "    x = tokenizer.encode_plus(df.loc[i].pn_history, max_length=SEQUENCE_LENGTH, padding='max_length',truncation=True, return_offsets_mapping=True)\n",
        "    input_ids.append(x['input_ids'])\n",
        "    attention_mask.append(x['attention_mask'])\n",
        "    offset_mapping.append(x['offset_mapping'])\n",
        "  return np.vstack(input_ids), np.vstack(attention_mask), offset_mapping"
      ],
      "metadata": {
        "id": "Tr2IjF7PbR_D"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = buildTrainingData(df)"
      ],
      "metadata": {
        "id": "U-CopLEkcIZZ",
        "outputId": "6f04b12b-6dfa-47bb-eb6e-f7fd1f2d9230",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14300/14300 [02:10<00:00, 109.47it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = TFAutoModel.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "id": "YQdckmJg2IE-",
        "outputId": "be36fc5f-789b-4f74-ea06-b1b737aae573",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tf.keras.layers.Input(shape = (SEQUENCE_LENGTH,), name = 'input_ids', dtype = tf.int32)\n",
        "attention_mask = tf.keras.layers.Input(shape = (SEQUENCE_LENGTH,), name = 'attention_mask', dtype = tf.int32)"
      ],
      "metadata": {
        "id": "YQKKUbxn2e_q"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_layer = bert_model(input_ids=input_ids,attention_mask=attention_mask)[0]"
      ],
      "metadata": {
        "id": "Vz27Ubn82hre"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#out = tf.keras.layers.Dense(20,activation='relu')(debert_layer)\n",
        "out = tf.keras.layers.Dropout(0.2)(bert_layer)\n",
        "out = tf.keras.layers.Dense(1, activation='sigmoid')(out)"
      ],
      "metadata": {
        "id": "mIhiNBz72kHg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Model(inputs = [input_ids, attention_mask], outputs=out)\n",
        "#model.layers[2].trainable = False"
      ],
      "metadata": {
        "id": "MIZAwamp2pTD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "1AoXM0-82sWj",
        "outputId": "dce73d6b-2146-43c2-e3d8-9afa06f8b526",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 512, 768)     0           ['tf_bert_model[0][0]']          \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512, 1)       769         ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,483,009\n",
            "Trainable params: 109,483,009\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.keras.losses.BinaryCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam(0.01)"
      ],
      "metadata": {
        "id": "R7rl5q6S2uXe"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=loss, optimizer=optimizer, metrics=['acc'])"
      ],
      "metadata": {
        "id": "ok1jb9XC2wBL"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hostory = model.fit(x = [data[0],data[1]], y = data[3], batch_size=5)"
      ],
      "metadata": {
        "id": "KB8f27mK2xgQ",
        "outputId": "d6f35b7e-3117-412d-86a4-7c3d7d0f3fd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "2860/2860 [==============================] - 3536s 1s/step - loss: 0.4310 - acc: 0.9710\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(data[2][0])[np.hstack(model.predict([data[0][0:1], data[1][0:1]])[0] >0.01)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiU0WTjpr-Kj",
        "outputId": "1bd5ae41-99c4-4895-ce3e-2c578877a160"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([], shape=(0, 2), dtype=int64)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.max(model.predict([data[0][0:10], data[1][0:10]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qzeap8pQq9h9",
        "outputId": "86d4f045-c9ba-4ac1-d401-54eb890c39bd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.6169253e-17"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HAUmhvpD7p8s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}